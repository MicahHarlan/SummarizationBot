Abstract
Artificial Intelligence (AI) at the edge is the utilization of AI in real-world devices. Edge AI refers to the practice of doing AI computations near the users at the network's edge, instead of centralised location like a cloud service provider's data centre. With the latest innovations in AI efficiency, the proliferation of Internet of Things (IoT) devices, and the rise of edge computing, the potential of edge AI has now been unlocked. This study provides a thorough analysis of AI approaches and capabilities as they pertain to edge computing, or Edge AI. Further, a detailed survey of edge computing and its paradigms including transition to Edge AI is presented to explore the background of each variant proposed for implementing Edge Computing. Furthermore, we discussed the Edge AI approach to deploying AI algorithms and models on edge devices, which are typically resource-constrained devices located at the edge of the network. We also presented the technology used in various modern IoT applications, including autonomous vehicles, smart homes, industrial automation, healthcare, and surveillance. Moreover, the discussion of leveraging machine learning algorithms optimized for resource-constrained environments is presented. Finally, important open challenges and potential research directions in the field of edge computing and edge AI have been identified and investigated. We hope that this article will serve as a common goal for a future blueprint that will unite important stakeholders and facilitates to accelerate development in the field of Edge AI.

1. Introduction
As IT developed after 2000, Cloud Computing was established as a novel computing infrastructure for the Internet based on highly resourced data centres. Interest in and adoption of cloud computing services has increased to the extent that global cloud IP traffic will account for more than 90% of total data centre traffic by 2020 [1]. The main advantages of the cloud computing paradigm remain “unlimited” storage capacity and computing resources, reduced capital expenditure and minimized carbon footprints [2].

However, this technology faces key issues: security, speed of services and slow connections, which are often combined as low bandwidth/high latency and jitter as mobile devices offload computational and processing capacity to cloud computing services [3,4]. These challenges have been exacerbated by the continued proliferation of mobile and fixed Internet-connected devices [5]. Problems of high latency and narrow bandwidths with reduced Quality of Experience (QoE) for users led to proposals to re-imagine the cloud: rather than being thought of as a homogeneous entity; the cloud would have a distinct “edge” separate from the core in which large-scale processing and storage would occur [6]. Devices could, therefore, communicate with local servers unless a need arose for contact with the cloud's core competencies [7]. This view was first articulated as the challenge to the rapidly increasing reliance on mega-data centres for hosting cloud computing [8]. These authors argued that geo-diverse multiple data centres would provide a superior model for applications such as email distribution, using “local” servers to filter out spam and blocking undesirable forms of traffic closer to their points of origin [9]. This formed, in effect, the first proposal for “edge” computing based on the deployment of “micro data centres” (mDCs) as advanced by Microsoft, Inc., which can be seen as a highly distributed cloud focused on mobile users and connected devices and requiring the installation of a global infrastructure of hardware sites, each with a limited number of servers (up to 10 per centre) and supplied with several terabytes of memory [8,10].

Shortly afterwards, the paradigm of the “cloudlet” for small numbers of casual and transient mobile device users in locations such as coffee shops and restaurants etc., was articulated [11]. A third concept developed from the increasing availability and use of fixed Internet-connected sensors (the “Internet of Things (IoT)”) requiring fast responses; this was structured as the “Fog Computing” (FC) paradigm [12].

Since 2011, mobile vendors have brought powerful smart mobile devices to change the fundamentals of how people interact with IT and telecommunications [13]. Due to significantly increased demands of mobile devices such as smartphones and tablets and because intensive mobile applications require high levels of processing and rely on remote data centres, accessing mobile services at “anytime, anywhere” increasingly clashes with users’ QoE and their sense of personal privacy and control [14].

By its very nature, Edge Computing must be accessible by (and respond to) a heterogeneous collection of devices in wireless networks: Wi-Fi, 3G, 4G, 5G and beyond [9]. To ensure the key essentials of low latency and high bandwidth in this highly flexible and highly changeable system, wireless interference must be minimized [15]. Fig. 1 presents the overall history of the edge computing paradigms from World Wide Web (WWW) to Edge Artificial Intelligence or Edge AI.

Mobile-access Edge Computing (MEC) initially emerged as an edge computing paradigm where a mobile user does not need to access cloud computing for data or computing capabilities in remote data centres but can use “edge” computing resources. The fundamentals were discussed in a white paper published by the European Telecommunications Standards Institute (ETSI) in 2014 [15]. The concept of MEC is simply to provide mobile and cloud computing services within close proximity of the mobile user, i.e. the provision of computing power in a delocalized manner close to mobile users (smartphones, tablets, etc.), aiming to decrease latency, achieve as high throughput as possible and provide direct access to real-time network information [16]. The renaming of MEC as Multi-access Edge Computing reflects aims for applications development in 2017 for non-mobile devices; this is a crucial change of direction and its full implications will be discussed later in this survey.1

Fig. 2 illustrates the four Edge Computing paradigms in three-tier hierarchies and shows where actual functionality can be implemented either at the end device or at the edge network [17]. FC end devices such as CCTVs can do some processing and send useful data to fog nodes to the fog's core. A simple Cloudlet server at the business premise can perform processing itself rather than at the end devices or in combination with end devices. An mDC processes multiple users’ requests locally [18]. Lastly, the concept of Mobile Cloud Computing (MCC) repeats many features of Cloud Computing but, because of the constraints of mobile devices (processing power and battery life), data processing is forwarded to cloud data centres and is therefore not Edge Computing.